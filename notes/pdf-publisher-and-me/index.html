<!doctype html> <html lang=en> <head> <meta charset=utf-8> <meta content="width=device-width,initial-scale=1" name=viewport> <meta content=#333333 name=theme-color> <base href=/ > <link href=global.css rel=preload as=style onload="this.onload=null;this.rel='stylesheet'"> <link href=//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css rel=preload as=style onload="this.onload=null;this.rel='stylesheet'"> <link href=manifest.json rel=manifest crossorigin=use-credentials> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,null,{post:{title:"PDFと、出版社と、私",date:"2021-12-23T05:00:00.000Z",tags:["advent"],slug:"pdf-publisher-and-me",html:"\u003Cp\u003Eこんにちは。Legalscape Co-founder &amp; CTOの城戸（きど）です。この記事は\u003Ca href=\"https:\u002F\u002Fqiita.com\u002Fadvent-calendar\u002F2021\u002Flegalscape\"\u003ELegalscape アドベントカレンダー 2021\u003C\u002Fa\u003Eの12\u002F23のエントリです。\u003C\u002Fp\u003E\n\u003Cp\u003E私たちが提供するリーガルリサーチツール「Legalscape」では、法令やパブコメ、ガイドライン、そして書籍などたくさんの種類の文献を扱っています。その上で逃れられないのが、PDFというポピュラーながら困りものなファイル形式の扱いです。今回は、なぜ私たちが、PDFという難敵とがっぷり四つに組んで戦うことに決めたのか、そしてそれはどんな戦いなのかの一端を伝えられたらと思います。\u003C\u002Fp\u003E\n\u003Ch1\u003EリーガルリサーチツールとPDFの切っても切れない関係\u003C\u002Fh1\u003E\n\u003Cp\u003E私たちが扱う文献は大きく分けて2つの出自を持っています。インターネットから収集したものと、出版社等コンテンツホルダーから直接提供いただいたものです。\u003C\u002Fp\u003E\n\u003Cp\u003E前者にはパブコメやガイドラインなど、官公庁がそれぞれのウェブサイト上で公開している資料が含まれます。こういった資料は、ご覧になった経験がある方も多いと思いますが、多くがPDFで公開されています。これらはPDFの形で入手し、活用せざるをえませんが、実は私たちにとってPDFはあまり嬉しい形式とも言えないというのが実情です。次節以降で詳しく語りますが、\u003Cstrong\u003EPDFは再利用性の低い、いわば最終成果物に過ぎない\u003C\u002Fstrong\u003Eからです。ITエンジニアの方であれば、「ビルドしたバイナリだけもらっても困るけど、ソースコードがあったら嬉しい」という比喩で伝わるでしょうか。\u003C\u002Fp\u003E\n\u003Cp\u003E話を戻して、では後者の、出版社からのデータはどうでしょうか。起稿から出版まで、全てを扱っている出版社から直接データをもらえるのであれば、PDFではなく、より使い勝手のいい、機械可読性の高い（コンピュータで処理しやすい）形式で手に入るのでしょうか。\u003C\u002Fp\u003E\n\u003Cp\u003E残念ながらこれは真ではありません。私はこの理由を知ったとき大変驚きました。なぜなら、\u003Cstrong\u003Eそもそも出版社は自社の出版物の電子データをPDF形式でしか持っていないことが少なくない\u003C\u002Fstrong\u003Eからです（個人の経験に基づく見解です。「うちは違うよ！」という指摘は甘んじて受けます）。なぜこんなことが起きるのでしょうか？　答えはシンプルです。そのような出版物は組版を出版社が自社ではやっておらず、印刷会社が担っているからです（個人の経験に基づく、以下略）。\u003C\u002Fp\u003E\n\u003Cp\u003EどうやらPDFからは逃れられそうにないということがわかってきました。ではそもそもPDFとはどういったファイル形式なのでしょうか。\u003C\u002Fp\u003E\n\u003Ch1\u003EPDFはなぜ私たちにとって厄介なのか\u003C\u002Fh1\u003E\n\u003Cp\u003EPDFはAdobeが開発した電子文書ファイル形式です。そして、国際標準である\u003Ca href=\"https:\u002F\u002Fwww.iso.org\u002Fstandard\u002F51502.html\"\u003EISO 32000\u003C\u002Fa\u003Eには「PDFの目的は利用者が電子文書を簡単かつ確実に、それらが作られた環境や、それらが閲覧・印刷される環境に依存せず、交換・閲覧できるようにすることである」と規定されています（鉤括弧内は拙訳）。すなわち、PDFは\u003Cstrong\u003E閲覧するためのファイル形式\u003C\u002Fstrong\u003Eなのです。\u003C\u002Fp\u003E\n\u003Cp\u003Eこのおかげで、出版物のような高い品質の文書を、あらゆる環境で、作成者が意図した通りに閲覧することができます。ですから、たとえば利用者にPDF文書を閲覧させるだけのWebサービスであれば、作るのはとても容易だと言えるでしょう。\u003C\u002Fp\u003E\n\u003Cp\u003Eですが、私たちのように書籍などの文献の内容を自然言語処理などの技術を用いて解析し、より高い価値を提供できるようにしたいと考えている人にとっては、話が違います。PDFはあらゆる環境で同じ見た目を再現するという目的に特化しているために、\u003Cstrong\u003E再利用が困難である\u003C\u002Fstrong\u003Eからです。\u003C\u002Fp\u003E\n\u003Ch1\u003EPDFには「テキストデータ」は含まれていない\u003C\u002Fh1\u003E\n\u003Cp\u003EPDF文書の内容を解析しようとするとき、まず初めに取り組まないといけないのがテキストの抽出です。一見簡単そうなタスクに思えますが、実は一筋縄ではいきません。\u003C\u002Fp\u003E\n\u003Cp\u003E先に、PDFは閲覧するためのファイル形式だと述べました。つまり、テキストデータを格納するためのファイル形式ではありません。ではどんな内部構造になっているのでしょうか。\u003C\u002Fp\u003E\n\u003Cp\u003E正確に説明すると非常に長くなるため、イメージだけ伝わるような説明をしますと、PDFは、機械語のように「描画位置を (x, y) に移動せよ」「フォントサイズを S に変更せよ」「ABC という文字を描画せよ」というような命令が羅列されたデータになっており、その命令を上から順に実行していくことでページを描画する仕組みになっています。そして「ABC という文字を描画せよ」という例を出しましたが、「F というフォントの 12345 番のグリフを描画せよ」と言った方が実態に近いです。グリフというのは大雑把にいうと一字一字の図形的なかたちのことです。要するに、閲覧する、すなわち画面や紙に表示するためのデータですから、その内容がどうであるということは関係なく、\u003Cstrong\u003Eどの図形を描画すればいいか\u003C\u002Fstrong\u003E、という指示だけが入っているということです。\u003C\u002Fp\u003E\n\u003Cp\u003Eこのような構造のPDF文書からテキスト抽出をするには、出現するグリフの番号が実際にどの文字なのかの対応づけをもとに図形から文字に変換してあげる必要があります。この対応づけが、UnicodeだとかASCIIだとかよくある既知の文字コードと一致していれば良いのですが、実際にはCIDやGIDと呼ばれるフォント独自の番号システムになっています。\u003C\u002Fp\u003E\n\u003Cp\u003EではPDF文書からのテキスト抽出は全く不可能か？　というとそういうわけでもありません。PDFにはCMapというCID\u002FGIDとUnicodeの対応表があり、これに照らしわせながら読めば実際のテキストを手に入れることができます。問題はこのCMapのデータが正しく指定されていないPDF文書です。\u003C\u002Fp\u003E\n\u003Cp\u003E私たちが実際に出版社から受領した書籍のPDF文書の中にも、一定の割合でCMapのデータが適切に含まれないものが混ざっていました。当然テキスト抽出するとまともなテキストは得られません。それどころか（同じ原理で、当たり前ですが）PDFビューアーで開いた上で文章をコピー＆ペーストしても壊れたデータしか手に入りません。PDF文書を印刷会社が作成したとき使われたソフトウェアの特性なのか、あるいはわざとそのようなオプションを指定したのか、……どうしてこのようなPDF文書が生まれたのかは、謎です。\u003C\u002Fp\u003E\n\u003Ch1\u003EPDF探求の旅は続く\u003C\u002Fh1\u003E\n\u003Cp\u003Eこういった複雑な内部構造を持つPDFから、どうにかテキストらしきものを抽出できたとしても、まだ苦労は終わりません。グリフのIDから文字に変換できたとはいえ、手に入る情報は「どの位置にどのテキストが描画されたか」というデータだけです。この状態で、得られたテキストはどこからどこまでが「行」なのでしょうか？　どこからどこまでが「段落」なのでしょうか？　いずれも座標やテキストのデータだけでは明らかではありません。何らかの方法で推定する必要があります。「段組」はどう扱えばいいのでしょうか？　「本文」と、「本文」以外の「ノンブル」（ページ番号のことです）「柱」（ページの上端や下端に章タイトルなどが書かれている箇所です）はどう区別すればいいでしょう？　さらに、テキスト以外にも「図」や「表」も重要な要素です。PDF解析の道のりは長く険しいのです。\u003C\u002Fp\u003E\n\u003Cp\u003EなおLegalscapeでは、すでに上記のようなPDF解析の一連の流れを可能にする、自動と人手を組み合わせたソフトウェアを開発し、順次法律文献の解析を進めています。これにより、\u003Ca href=\"https:\u002F\u002Fnote.com\u002Flegalscape\u002Fn\u002Fnb21cfd8bc0c2\"\u003E12\u002F1の八木田のエントリ\u003C\u002Fa\u003Eのように、単なるPDFやPDFを画像化したもののビューアーを超え、他製品では実現できない様々な機能を実現しています。\u003C\u002Fp\u003E\n\u003Ch1\u003E終わりに\u003C\u002Fh1\u003E\n\u003Cp\u003Eこの記事では、Legalscapeを裏から支えるPDF解析技術の事情について触れました。私たちのチームに加わって、自然言語処理などでそのデータを活用するために避けては通れないこの苦労を分かち合っていただき、法情報の本質的な利活用を可能にするべく、一緒に戦っていただける方を募集しています。\n\u003Ca href=\"https:\u002F\u002Flegalscape.notion.site\u002F09aeb478072946c18249495b8fb63fcd\"\u003E採用情報\u003C\u002Fa\u003Eをご覧いただけたら嬉しいです。\u003C\u002Fp\u003E\n",headline:"こんにちは。Legalscape Co-founder & CTOの城戸（きど）です。この記事は[Legalscape アドベントカレンダー 2021](https:\u002F\u002Fqiita.com\u002Fadve"},historyURL:"https:\u002F\u002Fgithub.com\u002Fkissge\u002Fyo.eki.do\u002Fcommits\u002Fmaster\u002Fnotes\u002Fpdf-publisher-and-me.md"}]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');(function(){try{eval("async function x(){}");var main="/client/client.b795f5c8.js"}catch(e){main="/client/legacy/client.a43cae97.js"};var s=document.createElement("script");try{new Function("if(0)import('')")();s.src=main;s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@2.0.4.js";s.setAttribute("data-main",main);}document.head.appendChild(s);}());</script> <link href=client/client-9e2cfc0b.css rel=stylesheet><link href=client/[slug]-f92f0c12.css rel=stylesheet> <title>PDFと、出版社と、私 - 2021-12-23 | 葉月夜堂</title><link href=https://twitter.com/p_km rel=me data-svelte=svelte-119a9vg> <link href=https://webmention.io/yo.eki.do/webmention rel=webmention data-svelte=svelte-119a9vg> <link href=https://webmention.io/yo.eki.do/xmlrpc rel=pingback data-svelte=svelte-119a9vg><meta content=article data-svelte=svelte-14mnzgr property=og:type><meta content="PDFと、出版社と、私 - 2021-12-23 | 葉月夜堂" data-svelte=svelte-14mnzgr property=og:title><meta content="こんにちは。Legalscape Co-founder & CTOの城戸（きど）です。この記事は[Legalscape アドベントカレンダー 2021](https://qiita.com/adve" data-svelte=svelte-14mnzgr property=og:description><meta content=葉月夜堂 data-svelte=svelte-14mnzgr property=og:site_name><meta content=https://yo.eki.do/images/default.png data-svelte=svelte-14mnzgr property=og:image> <link href=/client/client.b795f5c8.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/client-9e2cfc0b.css rel=preload as=style><link href=/client/[slug].dfe790e7.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/inject_styles.5607aec6.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/[slug]-f92f0c12.css rel=preload as=style></head> <body> <div id=sapper> <nav class=svelte-1vowuxu><ul class=svelte-1vowuxu><li class=svelte-1vowuxu><a href=. class=svelte-1vowuxu rel=prefetch>articles</a></li> <li class=svelte-1vowuxu><a href=about class=svelte-1vowuxu rel=prefetch>about</a></ul> </nav> <main class=svelte-gph4rb> <header class=svelte-bluf97><div class="svelte-bluf97 img-header" style=""></div> <h1 class=svelte-bluf97>PDFと、出版社と、私</h1> <time class=svelte-bluf97>2021-12-23<span class=date-weak>T</span>14:00:00<span class=date-weak>+09:00</span></time> <div class=tags><div class="svelte-bluf97 tag">#advent</div></div> <p class="svelte-bluf97 history"><a href=https://github.com/kissge/yo.eki.do/commits/master/notes/pdf-publisher-and-me.md>更新履歴</a></header> <div class="svelte-bluf97 content"><p>こんにちは。Legalscape Co-founder & CTOの城戸（きど）です。この記事は<a href=https://qiita.com/advent-calendar/2021/legalscape>Legalscape アドベントカレンダー 2021</a>の12/23のエントリです。</p> <p>私たちが提供するリーガルリサーチツール「Legalscape」では、法令やパブコメ、ガイドライン、そして書籍などたくさんの種類の文献を扱っています。その上で逃れられないのが、PDFというポピュラーながら困りものなファイル形式の扱いです。今回は、なぜ私たちが、PDFという難敵とがっぷり四つに組んで戦うことに決めたのか、そしてそれはどんな戦いなのかの一端を伝えられたらと思います。</p> <h1>リーガルリサーチツールとPDFの切っても切れない関係</h1> <p>私たちが扱う文献は大きく分けて2つの出自を持っています。インターネットから収集したものと、出版社等コンテンツホルダーから直接提供いただいたものです。</p> <p>前者にはパブコメやガイドラインなど、官公庁がそれぞれのウェブサイト上で公開している資料が含まれます。こういった資料は、ご覧になった経験がある方も多いと思いますが、多くがPDFで公開されています。これらはPDFの形で入手し、活用せざるをえませんが、実は私たちにとってPDFはあまり嬉しい形式とも言えないというのが実情です。次節以降で詳しく語りますが、<strong>PDFは再利用性の低い、いわば最終成果物に過ぎない</strong>からです。ITエンジニアの方であれば、「ビルドしたバイナリだけもらっても困るけど、ソースコードがあったら嬉しい」という比喩で伝わるでしょうか。</p> <p>話を戻して、では後者の、出版社からのデータはどうでしょうか。起稿から出版まで、全てを扱っている出版社から直接データをもらえるのであれば、PDFではなく、より使い勝手のいい、機械可読性の高い（コンピュータで処理しやすい）形式で手に入るのでしょうか。</p> <p>残念ながらこれは真ではありません。私はこの理由を知ったとき大変驚きました。なぜなら、<strong>そもそも出版社は自社の出版物の電子データをPDF形式でしか持っていないことが少なくない</strong>からです（個人の経験に基づく見解です。「うちは違うよ！」という指摘は甘んじて受けます）。なぜこんなことが起きるのでしょうか？　答えはシンプルです。そのような出版物は組版を出版社が自社ではやっておらず、印刷会社が担っているからです（個人の経験に基づく、以下略）。</p> <p>どうやらPDFからは逃れられそうにないということがわかってきました。ではそもそもPDFとはどういったファイル形式なのでしょうか。</p> <h1>PDFはなぜ私たちにとって厄介なのか</h1> <p>PDFはAdobeが開発した電子文書ファイル形式です。そして、国際標準である<a href=https://www.iso.org/standard/51502.html>ISO 32000</a>には「PDFの目的は利用者が電子文書を簡単かつ確実に、それらが作られた環境や、それらが閲覧・印刷される環境に依存せず、交換・閲覧できるようにすることである」と規定されています（鉤括弧内は拙訳）。すなわち、PDFは<strong>閲覧するためのファイル形式</strong>なのです。</p> <p>このおかげで、出版物のような高い品質の文書を、あらゆる環境で、作成者が意図した通りに閲覧することができます。ですから、たとえば利用者にPDF文書を閲覧させるだけのWebサービスであれば、作るのはとても容易だと言えるでしょう。</p> <p>ですが、私たちのように書籍などの文献の内容を自然言語処理などの技術を用いて解析し、より高い価値を提供できるようにしたいと考えている人にとっては、話が違います。PDFはあらゆる環境で同じ見た目を再現するという目的に特化しているために、<strong>再利用が困難である</strong>からです。</p> <h1>PDFには「テキストデータ」は含まれていない</h1> <p>PDF文書の内容を解析しようとするとき、まず初めに取り組まないといけないのがテキストの抽出です。一見簡単そうなタスクに思えますが、実は一筋縄ではいきません。</p> <p>先に、PDFは閲覧するためのファイル形式だと述べました。つまり、テキストデータを格納するためのファイル形式ではありません。ではどんな内部構造になっているのでしょうか。</p> <p>正確に説明すると非常に長くなるため、イメージだけ伝わるような説明をしますと、PDFは、機械語のように「描画位置を (x, y) に移動せよ」「フォントサイズを S に変更せよ」「ABC という文字を描画せよ」というような命令が羅列されたデータになっており、その命令を上から順に実行していくことでページを描画する仕組みになっています。そして「ABC という文字を描画せよ」という例を出しましたが、「F というフォントの 12345 番のグリフを描画せよ」と言った方が実態に近いです。グリフというのは大雑把にいうと一字一字の図形的なかたちのことです。要するに、閲覧する、すなわち画面や紙に表示するためのデータですから、その内容がどうであるということは関係なく、<strong>どの図形を描画すればいいか</strong>、という指示だけが入っているということです。</p> <p>このような構造のPDF文書からテキスト抽出をするには、出現するグリフの番号が実際にどの文字なのかの対応づけをもとに図形から文字に変換してあげる必要があります。この対応づけが、UnicodeだとかASCIIだとかよくある既知の文字コードと一致していれば良いのですが、実際にはCIDやGIDと呼ばれるフォント独自の番号システムになっています。</p> <p>ではPDF文書からのテキスト抽出は全く不可能か？　というとそういうわけでもありません。PDFにはCMapというCID/GIDとUnicodeの対応表があり、これに照らしわせながら読めば実際のテキストを手に入れることができます。問題はこのCMapのデータが正しく指定されていないPDF文書です。</p> <p>私たちが実際に出版社から受領した書籍のPDF文書の中にも、一定の割合でCMapのデータが適切に含まれないものが混ざっていました。当然テキスト抽出するとまともなテキストは得られません。それどころか（同じ原理で、当たり前ですが）PDFビューアーで開いた上で文章をコピー＆ペーストしても壊れたデータしか手に入りません。PDF文書を印刷会社が作成したとき使われたソフトウェアの特性なのか、あるいはわざとそのようなオプションを指定したのか、……どうしてこのようなPDF文書が生まれたのかは、謎です。</p> <h1>PDF探求の旅は続く</h1> <p>こういった複雑な内部構造を持つPDFから、どうにかテキストらしきものを抽出できたとしても、まだ苦労は終わりません。グリフのIDから文字に変換できたとはいえ、手に入る情報は「どの位置にどのテキストが描画されたか」というデータだけです。この状態で、得られたテキストはどこからどこまでが「行」なのでしょうか？　どこからどこまでが「段落」なのでしょうか？　いずれも座標やテキストのデータだけでは明らかではありません。何らかの方法で推定する必要があります。「段組」はどう扱えばいいのでしょうか？　「本文」と、「本文」以外の「ノンブル」（ページ番号のことです）「柱」（ページの上端や下端に章タイトルなどが書かれている箇所です）はどう区別すればいいでしょう？　さらに、テキスト以外にも「図」や「表」も重要な要素です。PDF解析の道のりは長く険しいのです。</p> <p>なおLegalscapeでは、すでに上記のようなPDF解析の一連の流れを可能にする、自動と人手を組み合わせたソフトウェアを開発し、順次法律文献の解析を進めています。これにより、<a href=https://note.com/legalscape/n/nb21cfd8bc0c2>12/1の八木田のエントリ</a>のように、単なるPDFやPDFを画像化したもののビューアーを超え、他製品では実現できない様々な機能を実現しています。</p> <h1>終わりに</h1> <p>この記事では、Legalscapeを裏から支えるPDF解析技術の事情について触れました。私たちのチームに加わって、自然言語処理などでそのデータを活用するために避けては通れないこの苦労を分かち合っていただき、法情報の本質的な利活用を可能にするべく、一緒に戦っていただける方を募集しています。 <a href=https://legalscape.notion.site/09aeb478072946c18249495b8fb63fcd>採用情報</a>をご覧いただけたら嬉しいです。</p> </div> <x-script async data-ad-client=ca-pub-5159408992513362 src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></x-script> <section class="svelte-bluf97 mentions"><h1 class=svelte-bluf97>Recent public mentions on Twitter</h1> <ol>Loading mentions...</ol> </section> </main></div> 