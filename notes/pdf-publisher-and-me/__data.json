{"type":"data","nodes":[null,{"type":"data","data":[{"entity":1},{"name":2,"nameSegmented":3,"kind":7,"urlPath":8,"historyURL":9,"lastModified":10,"attributes":11,"tags":16,"body":22,"headline":23,"links":24,"isEmpty":69},"PDFと、出版社と、私",[4,5,6],"PDFと、","出版社と、","私","note","/notes/pdf-publisher-and-me","https://github.com/kissge/yo.eki.do/commits/master/notes/pdf-publisher-and-me.md",["Date","2022-09-04T05:58:48.000Z"],{"title":2,"date":12,"tags":13},["Date","2021-12-23T05:00:00.000Z"],[14,15],"アドベントカレンダー","LegalTech",[17,20],{"name":14,"kind":18,"urlPath":19},"tag","/mono/%E3%82%A2%E3%83%89%E3%83%99%E3%83%B3%E3%83%88%E3%82%AB%E3%83%AC%E3%83%B3%E3%83%80%E3%83%BC",{"name":15,"kind":18,"urlPath":21},"/mono/LegalTech","\u003Cp>こんにちは。Legalscape Co-founder &amp; CTOの城戸（きど）です。この記事は\u003Ca href=\"https://qiita.com/advent-calendar/2021/legalscape\">Legalscape アドベントカレンダー 2021\u003C/a>の12/23のエントリです。\u003C/p>\n\u003Cp>私たちが提供するリーガルリサーチツール「Legalscape」では、法令やパブコメ、ガイドライン、そして書籍などたくさんの種類の文献を扱っています。その上で逃れられないのが、PDFというポピュラーながら困りものなファイル形式の扱いです。今回は、なぜ私たちが、PDFという難敵とがっぷり四つに組んで戦うことに決めたのか、そしてそれはどんな戦いなのかの一端を伝えられたらと思います。\u003C/p>\n\u003Ch1 id=\"リーガルリサーチツールとpdfの切っても切れない関係\">リーガルリサーチツールとPDFの切っても切れない関係\u003C/h1>\n\u003Cp>私たちが扱う文献は大きく分けて2つの出自を持っています。インターネットから収集したものと、出版社等コンテンツホルダーから直接提供いただいたものです。\u003C/p>\n\u003Cp>前者にはパブコメやガイドラインなど、官公庁がそれぞれのウェブサイト上で公開している資料が含まれます。こういった資料は、ご覧になった経験がある方も多いと思いますが、多くがPDFで公開されています。これらはPDFの形で入手し、活用せざるをえませんが、実は私たちにとってPDFはあまり嬉しい形式とも言えないというのが実情です。次節以降で詳しく語りますが、\u003Cstrong>PDFは再利用性の低い、いわば最終成果物に過ぎない\u003C/strong>からです。ITエンジニアの方であれば、「ビルドしたバイナリだけもらっても困るけど、ソースコードがあったら嬉しい」という比喩で伝わるでしょうか。\u003C/p>\n\u003Cp>話を戻して、では後者の、出版社からのデータはどうでしょうか。起稿から出版まで、全てを扱っている出版社から直接データをもらえるのであれば、PDFではなく、より使い勝手のいい、機械可読性の高い（コンピュータで処理しやすい）形式で手に入るのでしょうか。\u003C/p>\n\u003Cp>残念ながらこれは真ではありません。私はこの理由を知ったとき大変驚きました。なぜなら、\u003Cstrong>そもそも出版社は自社の出版物の電子データをPDF形式でしか持っていないことが少なくない\u003C/strong>からです（個人の経験に基づく見解です。「うちは違うよ！」という指摘は甘んじて受けます）。なぜこんなことが起きるのでしょうか？　答えはシンプルです。そのような出版物は組版を出版社が自社ではやっておらず、印刷会社が担っているからです（個人の経験に基づく、以下略）。\u003C/p>\n\u003Cp>どうやらPDFからは逃れられそうにないということがわかってきました。ではそもそもPDFとはどういったファイル形式なのでしょうか。\u003C/p>\n\u003Ch1 id=\"pdfはなぜ私たちにとって厄介なのか\">PDFはなぜ私たちにとって厄介なのか\u003C/h1>\n\u003Cp>PDFはAdobeが開発した電子文書ファイル形式です。そして、国際標準である\u003Ca href=\"https://www.iso.org/standard/51502.html\">ISO 32000\u003C/a>には「PDFの目的は利用者が電子文書を簡単かつ確実に、それらが作られた環境や、それらが閲覧・印刷される環境に依存せず、交換・閲覧できるようにすることである」と規定されています（鉤括弧内は拙訳）。すなわち、PDFは\u003Cstrong>閲覧するためのファイル形式\u003C/strong>なのです。\u003C/p>\n\u003Cp>このおかげで、出版物のような高い品質の文書を、あらゆる環境で、作成者が意図した通りに閲覧することができます。ですから、たとえば利用者にPDF文書を閲覧させるだけのWebサービスであれば、作るのはとても容易だと言えるでしょう。\u003C/p>\n\u003Cp>ですが、私たちのように書籍などの文献の内容を自然言語処理などの技術を用いて解析し、より高い価値を提供できるようにしたいと考えている人にとっては、話が違います。PDFはあらゆる環境で同じ見た目を再現するという目的に特化しているために、\u003Cstrong>再利用が困難である\u003C/strong>からです。\u003C/p>\n\u003Ch1 id=\"pdfには「テキストデータ」は含まれていない\">PDFには「テキストデータ」は含まれていない\u003C/h1>\n\u003Cp>PDF文書の内容を解析しようとするとき、まず初めに取り組まないといけないのがテキストの抽出です。一見簡単そうなタスクに思えますが、実は一筋縄ではいきません。\u003C/p>\n\u003Cp>先に、PDFは閲覧するためのファイル形式だと述べました。つまり、テキストデータを格納するためのファイル形式ではありません。ではどんな内部構造になっているのでしょうか。\u003C/p>\n\u003Cp>正確に説明すると非常に長くなるため、イメージだけ伝わるような説明をしますと、PDFは、機械語のように「描画位置を (x, y) に移動せよ」「フォントサイズを S に変更せよ」「ABC という文字を描画せよ」というような命令が羅列されたデータになっており、その命令を上から順に実行していくことでページを描画する仕組みになっています。そして「ABC という文字を描画せよ」という例を出しましたが、「F というフォントの 12345 番のグリフを描画せよ」と言った方が実態に近いです。グリフというのは大雑把にいうと一字一字の図形的なかたちのことです。要するに、閲覧する、すなわち画面や紙に表示するためのデータですから、その内容がどうであるということは関係なく、\u003Cstrong>どの図形を描画すればいいか\u003C/strong>、という指示だけが入っているということです。\u003C/p>\n\u003Cp>このような構造のPDF文書からテキスト抽出をするには、出現するグリフの番号が実際にどの文字なのかの対応づけをもとに図形から文字に変換してあげる必要があります。この対応づけが、\u003Ca href=\"/mono/Unicode\" class=\"monolog-link\"  title=\"Unicode\">Unicode\u003C/a>だとかASCIIだとかよくある既知の文字コードと一致していれば良いのですが、実際にはCIDやGIDと呼ばれるフォント独自の番号システムになっています。\u003C/p>\n\u003Cp>ではPDF文書からのテキスト抽出は全く不可能か？　というとそういうわけでもありません。PDFにはCMapというCID/GIDと\u003Ca href=\"/mono/Unicode\" class=\"monolog-link\"  title=\"Unicode\">Unicode\u003C/a>の対応表があり、これに照らしわせながら読めば実際のテキストを手に入れることができます。問題はこのCMapのデータが正しく指定されていないPDF文書です。\u003C/p>\n\u003Cp>私たちが実際に出版社から受領した書籍のPDF文書の中にも、一定の割合でCMapのデータが適切に含まれないものが混ざっていました。当然テキスト抽出するとまともなテキストは得られません。それどころか（同じ原理で、当たり前ですが）PDFビューアーで開いた上で文章をコピー＆ペーストしても壊れたデータしか手に入りません。PDF文書を印刷会社が作成したとき使われたソフトウェアの特性なのか、あるいはわざとそのようなオプションを指定したのか、……どうしてこのようなPDF文書が生まれたのかは、謎です。\u003C/p>\n\u003Ch1 id=\"pdf探求の旅は続く\">PDF探求の旅は続く\u003C/h1>\n\u003Cp>こういった複雑な内部構造を持つPDFから、どうにかテキストらしきものを抽出できたとしても、まだ苦労は終わりません。グリフのIDから文字に変換できたとはいえ、手に入る情報は「どの位置にどのテキストが描画されたか」というデータだけです。この状態で、得られたテキストはどこからどこまでが「行」なのでしょうか？　どこからどこまでが「段落」なのでしょうか？　いずれも座標やテキストのデータだけでは明らかではありません。何らかの方法で推定する必要があります。「段組」はどう扱えばいいのでしょうか？　「本文」と、「本文」以外の「ノンブル」（ページ番号のことです）「柱」（ページの上端や下端に章タイトルなどが書かれている箇所です）はどう区別すればいいでしょう？　さらに、テキスト以外にも「図」や「表」も重要な要素です。PDF解析の道のりは長く険しいのです。\u003C/p>\n\u003Cp>なおLegalscapeでは、すでに上記のようなPDF解析の一連の流れを可能にする、自動と人手を組み合わせたソフトウェアを開発し、順次法律文献の解析を進めています。これにより、\u003Ca href=\"https://note.com/legalscape/n/nb21cfd8bc0c2\">12/1の八木田のエントリ\u003C/a>のように、単なるPDFやPDFを画像化したもののビューアーを超え、他製品では実現できない様々な機能を実現しています。\u003C/p>\n\u003Ch1 id=\"終わりに\">終わりに\u003C/h1>\n\u003Cp>この記事では、Legalscapeを裏から支えるPDF解析技術の事情について触れました。私たちのチームに加わって、自然言語処理などでそのデータを活用するために避けては通れないこの苦労を分かち合っていただき、法情報の本質的な利活用を可能にするべく、一緒に戦っていただける方を募集しています。\u003Ca href=\"https://legalscape.notion.site/09aeb478072946c18249495b8fb63fcd\">採用情報\u003C/a>をご覧いただけたら嬉しいです。\u003C/p>\n","こんにちは。Legalscape Co-founder &amp; CTOの城戸（きど）です。この記事はLegalscape アドベントカレンダー 2021の12/23のエントリです。私たちが提供するリーガルリサーチツール「Legalscape」では、法令やパブコメ、ガイドライン、そして書籍などたくさんの種類の文献を扱っています。その上で逃れられないのが、PDFというポピュラーながら困りものなファイル形式の扱いです。今回は、なぜ私たちが、PDFという難敵とがっぷり四つに組んで戦うことに決めたのか、そしてそれはどんな戦いなのかの一端を伝えられたらと思います。リーガルリサーチツールとPDFの切っても切れない関係私たちが扱う文献は大きく分けて2つの出自を持っています。インターネットから収集したものと、出版社等コンテンツホルダーから直接提供いただいたものです。前者にはパブコメやガイドラインなど、官公庁がそれぞれのウェブサイト上で公開している資料が含まれます。こういった資料は、ご覧になった経験がある方も多いと思いますが、多くがPDFで公開されています。これらはPDFの形で入手し、活用せざるをえませんが、実は私たちにとっ",{"to":25,"from":39,"kind":41,"one_hop_Unicode":43,"one_hop_アドベントカレンダー":70,"one_hop_LegalTech":143},{"urlPath":8,"entities":26},[27,33,36],{"name":28,"nameSegmented":29,"kind":18,"urlPath":30,"tags":31,"isEmpty":32},"Unicode",[28],"/mono/Unicode",[],true,{"name":14,"nameSegmented":34,"kind":18,"urlPath":19,"tags":35,"isEmpty":32},[14],[],{"name":15,"nameSegmented":37,"kind":18,"urlPath":21,"tags":38,"isEmpty":32},[15],[],{"urlPath":8,"entities":40},[],{"urlPath":8,"entities":42},[],{"urlPath":30,"entities":44},[45],{"name":46,"nameSegmented":47,"kind":7,"urlPath":61,"historyURL":62,"lastModified":63,"attributes":64,"tags":67,"isEmpty":69},"ja-JP-u-ca-japaneseって何？ UnicodeのCLDRを読んでみよう（あるいは、JavaScriptで和暦を得る簡単なテクについて）",[48,49,50,51,52,53,54,55,56,57,58,59,60],"ja-JP-u-ca-japaneseって","何？"," Unicodeの","CLDRを","読んで","みよう","（あるいは、","JavaScriptで","和暦を","得る","簡単な","テクに","ついて）","/notes/cldr","https://github.com/kissge/yo.eki.do/commits/master/notes/cldr.md",["Date","2022-06-11T11:32:20.000Z"],{"title":46,"date":65,"tags":66},["Date","2022-02-19T02:41:00.000Z"],[28],[68],{"name":28,"kind":18,"urlPath":30},false,{"urlPath":19,"entities":71},[72,86,103,117,130],{"name":73,"nameSegmented":74,"kind":7,"urlPath":78,"historyURL":79,"lastModified":80,"attributes":81,"tags":84,"isEmpty":69},"リーガルリサーチシステム「Legalscape」の技術スタック2021",[75,76,77],"リーガルリサーチシステム","「Legalscape」の","技術スタック2021","/notes/legalscape-tech-stack","https://github.com/kissge/yo.eki.do/commits/master/notes/legalscape-tech-stack.md",["Date","2022-06-11T07:33:39.000Z"],{"title":73,"date":82,"tags":83},["Date","2021-12-02T00:00:00.000Z"],[14],[85],{"name":14,"kind":18,"urlPath":19},{"name":87,"nameSegmented":88,"kind":7,"urlPath":94,"historyURL":95,"lastModified":96,"attributes":97,"tags":101,"isEmpty":69},"来年こそは届いてほしいスマートグラス「Vue」",[89,90,91,92,93],"来年こそは","届いて","ほしい","スマートグラス","「Vue」","/notes/crowdfunding-vue","https://github.com/kissge/yo.eki.do/commits/master/notes/crowdfunding-vue.md",["Date","2022-06-11T07:34:19.000Z"],{"from":98,"title":87,"date":99,"tags":100},"wordpress",["Date","2018-12-13T00:17:07.000Z"],[14],[102],{"name":14,"kind":18,"urlPath":19},{"name":104,"nameSegmented":105,"kind":7,"urlPath":109,"historyURL":110,"lastModified":111,"attributes":112,"tags":115,"isEmpty":69},"Emacs: Windowsでやっていく2017",[106,107,108],"Emacs: Windowsで","やっていく","2017","/notes/emacs-windows-2017","https://github.com/kissge/yo.eki.do/commits/master/notes/emacs-windows-2017.md",["Date","2022-07-02T05:00:46.000Z"],{"from":98,"title":104,"date":113,"tags":114},["Date","2017-12-08T00:00:08.000Z"],[14],[116],{"name":14,"kind":18,"urlPath":19},{"name":118,"nameSegmented":119,"kind":7,"urlPath":122,"historyURL":123,"lastModified":124,"attributes":125,"tags":128,"isEmpty":69},"Emacs: まだターミナルで消耗してるの？",[120,121],"Emacs: まだターミナルで","消耗してるの？","/notes/tramp-mode","https://github.com/kissge/yo.eki.do/commits/master/notes/tramp-mode.md",["Date","2022-06-11T07:33:39.000Z"],{"from":98,"title":118,"date":126,"tags":127},["Date","2015-12-04T23:00:02.000Z"],[14],[129],{"name":14,"kind":18,"urlPath":19},{"name":131,"nameSegmented":132,"kind":7,"urlPath":135,"historyURL":136,"lastModified":137,"attributes":138,"tags":141,"isEmpty":69},"Emacs: re-builder + foreign-regexp.elでたのしい正規表現",[133,134],"Emacs: re-builder + foreign-regexp.elでたのしい","正規表現","/notes/foreign-regexp-el","https://github.com/kissge/yo.eki.do/commits/master/notes/foreign-regexp-el.md",["Date","2022-06-11T07:52:23.000Z"],{"from":98,"title":131,"date":139,"tags":140},["Date","2014-12-19T23:30:53.000Z"],[14],[142],{"name":14,"kind":18,"urlPath":19},{"urlPath":21,"entities":144},[145],{"name":146,"nameSegmented":147,"kind":7,"urlPath":148,"historyURL":149,"lastModified":150,"attributes":151,"tags":156,"isEmpty":69},"Introduction to Legal NLP",[146],"/notes/lnlp","https://github.com/kissge/yo.eki.do/commits/master/notes/lnlp.md",["Date","2023-03-04T14:34:01.000Z"],{"title":146,"date":152,"lang":153,"slides":32,"tags":154},["Date","2022-09-04T03:30:00.000Z"],"en",[155,15],"NLP",[157,159],{"name":155,"kind":18,"urlPath":158},"/mono/NLP",{"name":15,"kind":18,"urlPath":21}],"uses":{"url":1}}]}
